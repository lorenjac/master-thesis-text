Transactions are a powerful concept that has been adopted in various branches of
computer science. Examples include databases, transactional memory, and
operating systems. With transactions, multiple operations, such as reading or
updating a record, can be grouped into a single unit that succeeds if and only
if neither of its operations fails. Especially in high-performance computing
environments, the utilization of computing resources through concurrent
transactions plays an essential role.

This section introduces the concept of transactions and its properties with
regard to concurrency, in particular.

\paragraph{Definition}

A transaction is a sequence of operations that is treated as a single atomic
operation, i.e. it either succeeds if all its suboperations succeed or it fails.
In general, an incomplete or failed transaction must not have any observable
side effects. A transaction \emph{commits} when all its subordinate operations
have completed. Once this process is complete, the transaction is
\emph{committed} and all its side effects, if any, become visible.

In general, the concept of a transaction does not impose any restrictions on the
kind of operation enclosed inside a transaction. That is, apart from primitive
operations such as read or update, transactions may also consist of inner
transactions as well. This concept is known as \emph{nested} transactions
\cite{gray1981transaction}. In contrast, \emph{flat} transactions only permit
primitive operations.

Despite their general nature, nested transactions are not a subject of
discussion in this thesis, for a couple of reasons. First, nesting has been
found useful primarily for distributed transaction systems and transactional
programming models neither of which are within the scope of this work
\cite{moss1981nested, moss2006open}. In addition to implementation issues, there
are several semantic models for nesting which further complicates its discussion
\cite{harder1993concurrency, weikum1992concepts}. In the end, nesting has not
found wide adoption with the prominent exception of transactional memory
\cite{moss2006nested, moravan2006supporting, jacobi2012transactional} and a few
databases \cite{olson1999berkeley}. Hence, unless stated otherwise, the term
transaction always refers to flat transactions.

Especially when discussing concurrent transactions, a meaningful notation is
required to describe their interactions. For this purpose, the concept of a
\emph{schedule} is used. A schedule is a list of operations enclosed in one or
more transactions. Within a schedule, all operations appear in the same order
they are executed. Although there seems to be no standard notation, the
operations of a schedule typically comprise abstract operations for reading and
writing a record, as well as the basic transactional primitives of commit and
abort. A transaction is implicitly started by its first operation, so there is
no need for an explicit primitive. In order to make schedules more readable,
operations are denoted by shorthands as shown in Table
\ref{tab:schedule_notation}.

\begin{figure}[h!]
    \centering
    \begin{tabular}{|c|l|}
        \hline
        \textbf{Notation} & \textbf{Operation}\\
        \hline
        r(A) & Read a record A  \\ \hline
        w(A) & Write a record A \\ \hline
        c    & Commit           \\ \hline
        a    & Abort            \\
        \hline
    \end{tabular}
    \caption{}
    \label{tab:schedule_notation}
\end{figure}

There are several ways to print a schedule. A common method is to render a
linear list containing shorthands of indexed operations where the indices denote
the associated transaction, respectively (see Figure
\ref{fig:schedule_interleaved}).

\begin{figure}[h!]
    \centering
    \[
        r_1(A)\; r_2(A)\; w_2(A)\; c_2\; w_1(A)\; c_1
    \]
    \caption{Interleaved notation of a write-write conflict.}
    \label{fig:schedule_interleaved}
\end{figure}

For the better readability, this work chooses to list operations for each transaction invidually, while retaining their global chronological order as shown in Figure \ref{fig:schedule_projected}.

\begin{figure}[h!]
    \centering
    \begin{tabular}{r c c c}
        $t_1:$ & $r(A)$ &                     & $w(A)\; c$ \\
        $t_2:$ &        & $r(A)$\; $w(A)\; c$ &            \\
    \end{tabular}
    \caption{Projected version of Figure \ref{fig:schedule_interleaved}.}
    \label{fig:schedule_projected}
\end{figure}

\paragraph{Applications}

Transactions are useful when a series of operations must either execute in
conjunction or not at all. A simple example is the transfer between bank
accounts. The action of withdrawing a value from one account and depositing it
on another comprises two separate actions that must both be successful in order
to take effect.

The predominant domain of transactions is databases where they are used to
achieve consistent and reliable data access. However, there were also attempts
to establish transactional semantics as an operating system feature
\cite{porter2009operating, spinellis2009user, black1991understanding}. This way,
subsequent system calls could be executed as a unit and be undone if one of them
fails. Another application that sees increasing attention is transactional
memory which aims to provide a synchronization alternative to locking
\cite{knight1986architecture, herlihy1993transactional, shavit1997software}.
With regard to this thesis, recent use cases include transactions in a MMDB
\cite{leis2014exploiting} and durable updates to NVRAM
\cite{volos2011mnemosyne}. Despite being an intriguing concept, transactional
memory is beyond the scope of this work. Instead this work sets its focus on
plain software-based transactions in the field of databases and KVS, in
particular.

\paragraph{Transactional Semantics}

The previous definition of transactions was of rather intuitive nature. However,
in order to be useful, the semantics of a transaction need to be described more
precisely. The predominant characterization of transactional semantics is ACID
\cite{gray1981transaction, haerder1983principles}. It comprises a set of necessary properties:

\begin{itemize}
    \item Atomicity
    \item Consistency
    \item Isolation
    \item Durability
\end{itemize}

Atomicity captures the all-or-nothing notion of a transaction, i.e. either all
operations in its context succeed or none. As a consequence, any already
completed operation of a transaction must be undone should the latter fail.
Reverting the affected data to their previous state is often referred to as
\emph{rollback}.

The property of consistency asserts that if the underlying data are in a
consistent state, then any transaction must preserve consistency. For example,
an ACID-compliant database cannot be transitioned into an illegal state by means
of a transaction. If  a transaction is bound to break the consistency of the
database, then it has to be aborted and rolled back.

In case multiple transactions are executed concurrently, each transaction could
observe intermediate side effects of other concurrent transactions. In order to
prevent this scenario and ensure the consistency property, isolation precludes
transactions from seeing any concurrent activity. The property of isolation is
later dealt with in more detail.

The last of the four ACID properties is durability. It ensures that all side
effects incurred by a committed transaction must be durable across any
subsequent system failure. Durability can be very hard to enforce, especially in
the face of catastropic failures with failing backup media. Therefore its notion
is often relaxed to a reasonable extent.

The ACID criteria have become the prevalent reference for characterizing
transactional systems. However, not all systems enforce the complete set of
properties. Notable examples are transactional memory for conventional RAM and
some cache-like databases which do not support durability as they are volatile
by design. A prominent example for relaxation that is also fundamental to this thesis is the isolation of concurrent transactions.

\paragraph{Serial Transactions}

In a serial transaction-processing system all transactions are executed in a
sequential order. That is, only one transaction, if any, is being executed at a
time and overlapping is not possible. If a transaction $t_1$ attempts to start
while another transaction $t_0$ is still active then $t_1$ has to wait until
$t_0$ terminates.

This reveals two important drawbacks. First, transaction throughput does not
scale as the number of overlapping transaction requests increases. Second, with
only one computing resource active at a time, resource utilization is low on
multi-core architectures. The same is true on single-core systems as execution
latencies cannot be hidden by switching to other transactions. To mitigate these
issues, transactions can be allowed to run concurrently.

\paragraph{Concurrent Transactions}

Concurrent transaction execution can largely remove the shortcomings outlined above. Now, an incoming transaction does not need to wait for an in-flight transaction to complete. In addition to increasing transaction throughput, it also enables better resource utilization. This works as long as data are read but not written. Allowing concurrent updates however, bears potential conflicts that threaten the consistency of data and must therefore be addressed. Possible conflicts are:

\begin{itemize}
    \item write-write
    \item write-read
    \item read-write
\end{itemize}

When a transaction $t_1$ attempts to update a record $A$ that was previously
written but not committed by another transaction $t_2$ then $t_1$'s update could
overwrite $t_2$'s update to $A$ before it has become visible. Unaware of the
condition $t_2$ will successfully commit even though its update is lost (see
Figure \ref{fig:ww-conflict}). This situation is called a \emph{write-write}
conflict.

\begin{figure}[h!]
    \centering
    \begin{tabular}{r c c c}
        $t_1:$ &        & $w(A)\; c$ &     \\
        $t_2:$ & $w(A)$ &            & $c$ \\
    \end{tabular}
    \caption{A write-write conflict resulting in a lost update for $t_2$.}
    \label{fig:ww-conflict}
\end{figure}

A \emph{write-read} conflict occurs when a transaction reads data that has not
been committed yet. Imagine a transaction $t_1$ that reads a record $A$ that was
previously updated but not committed by another transaction $t_2$. If $t_2$
updates the same item again or fails, then $t_1$ has processed a value that was
never committed. This situation is also called \emph{dirty read}. For an example see Figure \ref{fig:wr-conflict}.

\begin{figure}[h!]
    \centering
    \begin{tabular}{r c c c}
        $t_1:$ &        & $r(A)\; w(B)$ & $c$ \\
        $t_2:$ & $w(A)$ & $a$           &     \\
    \end{tabular}
    \caption{A write-read conflict resulting in an erroneous update for $t_1$.}
    \label{fig:wr-conflict}
\end{figure}

The last conflict is called \emph{read-write} conflict and denotes a situation
when a transaction updates a record that was previously read by another
transaction that is still running. Consider two transactions $t_1$, $t_2$ where
$t_1$ reads a record $A$ which is later updated by $t_2$ before either
transaction commits. If $t_1$ reads $A$ again, then the result may be
inconsistent with the earlier read as shown in Figure \ref{fig:rw-conflict}. The
situation is also referred to as \emph{inconsistent read} or
\emph{non-repeatable read}.

\begin{figure}[h!]
    \centering
    \begin{tabular}{r c c c c}
        $t_1:$ & $r(A)$ &        &     & $r(A)$ \\
        $t_2:$ &        & $w(A)$ & $c$ &        \\
    \end{tabular}
    \caption{A read-write conflict resulting in an inconsistent read for $t_1$.}
    \label{fig:rw-conflict}
\end{figure}

Note that, since isolation must be guaranteed for the entire lifetime of a
transaction, conflicts are not precluded by protecting individual read or update
operations. Instead, a dedicated synchronization mechanism for transactions is
needed. An important formalism in this regard is serializability.

\paragraph{Serializability}

A core concept to preserve consistency in the presence of concurrent
transactions is \emph{serializability}. It is based on the observation that in
an ACID-compliant serial transaction processing system, every sequence of
transactions always yields consistent data. Likewise, a schedule of concurrent
transactions should yield consistent data if it behaves in a way that is
equivalent to a serial sequence of the same transactions.

More precisely, a concurrent schedule is called \emph{serializable} if and only
if there exists a serial schedule of the same transactions that produces the
same output. A transaction processing system provides serializability if and
only if it guarantees that all its concurrent schedules are serializable.

\todo[inline]{Examples}

In order to enforce serializability, a decidable classification for serial
transaction schedules is required. An early definition of serializability
appeared in ANSI SQL \cite{ansi1992sql, melton1993understanding}. The idea
is to identify and detect \emph{anomalies} of non-serializable schedules at
runtime. If an anomaly is detected then any affected transaction must fail.
Based on whether these anomalies were permitted, several \emph{isolation levels}
were defined. In terms of ANSI SQL, a transaction is serializable if none of the
following anomalies was present:

\begin{itemize}
    \item Dirty Read
    \item Non-Repeatable Read
    \item Phantom
\end{itemize}

A \emph{phantom} is similar to a non-repeatable read but differs in that the
item in question is not modified but added or removed. Imagine a transaction
$t_1$ making a conditional selection of items. If another transaction $t_2$ adds
an item and $t_1$ repeats its selection then the result may contain the item
which is inconsistent with the first result.

Note that this formalization is built around the observable artifacts of
non-serializable schedules, rather than their cause such as read-write
conflicts. While it is pragmatic to address only observable anomalies it is also
unreliable as more complicated consistencies may remain undetected. In fact, it
was later found that the above characterization is insufficient as further
anomalies were discovered \cite{berenson1995critique, fekete2004read}. In the
wake of these findings, additional restrictions were imposed on the notion of
serializability.

Nevertheless, all of the discovered anomalies can be attributed to the access
conflicts shown above. For example, the most recently discovered anomalies,
\emph{write skew} and \emph{non-serializable read-only} are essentially results
of read-write conflicts. In this sense, a transaction is serializable if and
only if all possible conflicts are precluded. This characterization has several
advantages. Most importantly, it is more plausible to discuss non-serializable
schedules in terms of causes instead of effects. In addition, as opposed to
anomalies the number of conflicts is smaller and also fixed. Therefore, this
thesis primariliy defines serializability in terms of conflicts.

\todo[inline]{Conflict-Freedom seems to be stronger than Serializability}
