\chapter{Key-Value Stores}
\label{ch:kvs}

A prominent use case for NVRAM are main-memory databases. Even though main
memory and processor caches have become more affordable, MMDB still suffer from
recovery on slower disk drives \cite{oukid2015instant, schwalb2016hyrise}. NVRAM
on the other hand, provides an opportunity to eliminate recovery altogether. An
important class of databases often implemented as MMDB is KVS. Due to their
simplicity and low overhead, KVS have been adopted both in big-data computing
and database research \cite{decandia2007dynamo, lakshman2010cassandra,
wang2015hydradb}. In recent works, KVS were used to explore database design for
NVRAM \cite{bailey2013exploring, zhou2016nvht, wu2016nvmcached}.

This chapter provides a domain analysis of KVS. First, a brief overview of KVS
is given. The aim of this work is to exploit NVRAM for a KVS with fast
conflict-free concurrent transactions. Therefore, a substantial part of the
remaining chapter is dedicated to transactions and concurrency control. The
chapter is concluded with an examination of existing KVS for NVRAM.

\section{Overview}

KVS form an integral part in modern database technology \cite{fiebig2016one}.
This section gives an overview of their properties, classes, and applications.
Compared to other types of databases, KVS are very simple databases that are
sometimes better described by what they are not or do not provide.

\begin{itemize}
    \item non-relational data model
    \item no data schemas
    \item no query languages
\end{itemize}

In general, a KVS consists of a single associative container, where each key is
mapped to exactly one value. A key is an arbitrary string with possible
restrictions on its length. In terms of relational databases, KVS comprise a
single table of two columns. As a result, much of the structural complexity
adherent to relational DBMS is omitted, thus making way for profound
optimization and better response times. Common data structures for associativity
in KVS are hash tables and search trees, in particular B-trees.

Unlike traditional databases, KVS do not impose data schemas. Consequently,
arbitrary chunks of data can be stored as values which is especially useful
in scenarios with no fixed data format or when enforcing one is not a priority.

\begin{lstlisting}
| user | Max                  |
| auth | dxlf240r0g7jr4u8n2oe |
| ...  | ...                  |
\end{lstlisting}

Furthermore, KVS do not provide query languages such as SQL to
store and retrieve data. Instead, KVS are accessed programmatically through a
concise set of operations which is why KVS are also referred to as
\emph{embedded} databases. Although their API is not standardized, it can be
essentially broken down to the following operations.

\begin{itemize}
    \item open/close
    \item insertion
    \item retrieval
    \item removal
\end{itemize}

\paragraph{Applications}

Traditional DBMS are often based on complex architectures featuring query
frontends and sophisticated storage mechanisms. While this works well in many
cases, it severely limits the performance in situations where a simpler storage
paradigm (e.g. key-value pairs) is sufficient. As a consequence, high access
latencies and convoluted, error-prone concurrency schemes inhibit the
scalability of storage systems. KVS on the other hand are designed to compensate
for these shortcomings. A driving force in this regard, are large internet
platforms, e-commerce for instance, and cloud computing services.

A longstanding example of a KVS is BerkeleyDB which acts as a database in a
variety of software solutions. Apart from open-source software such as OpenLDAP
or Apache Web server, BerkeleyDB is also used in a number of proprietary
software such as messaging servers, switches, and routers
\cite{kaestner2007aspect, olson1999berkeley}.

A more recent use case are distributed in-memory caches often found in big-data
environments. Web caches have received great attention as service providers
struggle to scale with rising traffic where many requests target only a small
amount of data \cite{xu2014characterizing}. With caching, a dedicated eviction
policy ensures that \emph{relevant} items reside in memory. As a result, caching
can improve response times significantly. For this purpose, KVS provide an
appropriate abstraction. Important representatives of this class are Redis
\cite{redis2017home} and memcached \cite{memcached2017home}. Not only have these
KVS been deployed at companies such as Facebook or Twitter, but they have also
formed the basis for substantial amounts of research in this area
\cite{xu2014characterizing}. Examples include FPGA acceleration
\cite{lavasani2014fpga}, memory partitioning for better cache hit rates
\cite{carra2014memory}, and NVRAM integration \cite{wu2016nvmcached,
malinowski2017using, venkataraman2011consistent}. Still, large companies tend to
maintain in-house solutions to suit their needs \cite{chang2008bigtable,
decandia2007dynamo, lakshman2010cassandra, wang2015hydradb}.

Beyond databases and caches, KVS have also been proposed as a basis for file
systems. In the past, there have been several attempts to integrate database
concepts into file systems, some of which are logging \cite{rosenblum1992design,
tweedie1998journaling} and transactions \cite{seltzer1990transaction,
wright2007extending, spillane2009enabling}. Some studies even suggest that
traditional hierarchical file systems may often be suboptimal
\cite{stein2005stupid, seltzer2009hierarchical}. While databases in general are
still considered too heavy-weight for use in file systems
\cite{seltzer2009hierarchical}, KVS may be a viable alternative. Examples
include the network file system DBFS which is based on BerkeleyDB
\cite{murphy2002design} and FlatFS, a simple file system for NVRAM
\cite{volos2014aerie}. In addition, KVS are also used to complement file
systems, for example, to store metadata as in PVFS \cite{carns2009small}. Still,
the predominant use case of KVS is found in light-weight databases and caches on
top of existing file systems.

\paragraph{Transactions}

An essential feature of most databases is transactions. Transactions enable a
sequence of database operations to appear as a single atomic operation. If a
single operation involved in a transaction fails, the entire transaction fails and its side effects are rolled back.

Transactions are a powerful mechanism that enables aggregated operations without
worrying about inconsistencies even in case of failure. Given the prevalence of
transactions, most KVS support them. Due to their importance for this work,
transactions are covered in more detail in the next section.

\paragraph{In-Memory Operation}

The performance of a database is often denoted in terms of transaction
throughput. One way to increase throughput is to mitigate data access latencies.
Apart from faster storage, this can be done by placing the entire database in
main memory which enables speedups by multiple orders of magnitude. This
approach, which dates back to the mid 1980s has been adopted in many
high-performance databases such as the more recent HANA database
\cite{molina1992main, faerber2012hana}. Likewise, most KVS are explicitly
designed for in-memory operation. Notable exceptions are the popular BerkeleyDB
or Apache's Cassandra where in-memory operation is only an option
\cite{bdb2017doc, lakshman2010cassandra}.

\paragraph{Concurrency}

Another approach to increase transaction throughput is to utilize multi-core
processors by executing transactions concurrently. In order to achieve maximum
performance, it is common for main-memory databases to also support concurrency
\cite{grund2010hyrise, faerber2012hana, diaconu2013hekaton}. Further, it has
been shown that KVS can gain substantial performance benefits through
concurrency \cite{fan2013memc3, li2015architecting, xu2014building}. In fact,
most KVS natively support concurrency with the exception of Redis
\cite{redis2017home}. Unfortunately, concurrency also introduces new issues such
as inconsistencies through race conditions on shared data. Mitigating this issue
can degrade performance which is why many designs trade full consistency against
faster relaxations \cite{decandia2007dynamo}. This issue is dealt with in the
next section about transactions.

\paragraph{Distributed Databases}

As mentioned earlier, KVS play a crucial role in big-data environments. Since
availability is often a requirement in this area, KVS are often implemented as
distributed services \cite{decandia2007dynamo, lakshman2010cassandra,
wang2015hydradb}. Distributed databases and their mechanisms such as distributed
transactions are beyond the scope of this work.

\section{Transactions}

Transactions are a powerful concept that has been adopted in various branches of
computer science. With transactions, multiple operations, such as reading or
updating a record, can be grouped into a single unit that succeeds if and only
if neither of its operations fails. Especially in high-performance computing
environments, the utilization of computing resources through concurrent
transactions plays an essential role.

This section introduces the concept of transactions and its properties with
regard to concurrency, in particular.

\paragraph{Definition}

A transaction is a sequence of operations that is treated as single atomic
operation, i.e. it either succeeds if all its suboperations succeed or it fails.
In general, an incomplete or failed transaction must not have any observable
side effects. A transaction *commits* when all its subordinate operations have
completed. Once this process is complete, the transaction is *committed* and all
its side effects, if any, become visible.

In general, the concept of a transaction does not impose any restrictions on the
kind of operation enclosed inside a transaction. That is, apart from primitive
operations such as read or update, transactions may also consist of transactions
as well. This concept is known as *nested* transactions. In contrast, only
primitive operations are permitted for *flat* transactions. Since nested
transactions are more complex in their nature and have not been widely adopted,
they are not subject of this work \cite{?}. Unless stated otherwise, the term
transaction always refers to flat transactions.

Transactions are useful when a series of operations must either execute in
conjunction or not at all. A simple example is the transfer of money from one
bank account to another. The action of withdrawing and depositing a specified
value comprises two separate actions that must be successful in conjunction or
not at all. Still, as shown later, even single operations can benefit from
transactional semantics.

\paragraph{Transactional Semantics}

The previous definition of transactions was of rather intuitive nature. However,
in order to be useful the semantics of a transaction need to be described more
precisely. The predominant characterization of transactional semantics is ACID
\cite{haerder1983}. It comprises a set of necessary properties:

\begin{itemize}
    \item atomicity
    \item consistency
    \item isolation
    \item durability
\end{itemize}

Atomicity captures the notion of all-or-nothing, i.e. either all operations of a
transactional context succeed or none at all. As a consequence, any already
completed operation of a transaction must be undone if the latter fails.
Reverting the affected data to their previous state is often referred to as
*rollback*.

The property of consistency asserts that if the underlying data are in a
consistent state, then any transaction must preserve consistency. For example,
an ACID-compliant database cannot be transitioned into an illegal state by means
of a transaction. If  a transaction is bound to break the consistency of the
database, then it has to be aborted and rolled back.

In case multiple transactions are executed concurrently, each transaction may
observe intermediate side effects of other concurrent transactions. In order to
prevent this scenario and ensure the consistency property, isolation precludes
transactions from seeing any concurrent activity. The property of isolation is
later dealt with in more detail.

The last of the four ACID properties is durability. It ensures that all side
effects incurred by a committed transaction must be durable across any
subsequent system failure. Durability can be very hard to enforce, especially in
the face of catastropic failures with failing backup media. Therefore its notion
is often relaxed to a reasonable extent.

The ACID criteria have become the prevalent measure to characterize
transactionial semantics. Although often associated with synchronization of
concurrent transactions, ACID is also useful in simpler scenarios. An example is
atomicity which captures the essence of a transaction even when the latter
comprises no more than two operations. Moreover, even a transaction that
consists of a single operation can benefit from ACID-compliance as it guarantees
that any modifications become durable if and only if the enclosing transaction
commits. Clearly though, the isolation property is central to preserving
consistency in the presence of concurrent transactions. In that regard,
isolation is the equivalent of consistency for concurrency.

\paragraph{Concurrent Transactions}

The performance of transaction processing systems such as databases is generally
denoted by their transaction throughput, i.e. the number of transactions
executed in a certain time frame. There are several approaches to increasing
transaction throughput, one being concurrency. In theory, the throughput
improvement on multi-core systems is linear in the number of available cores.
However, there are several factors to consider, some of which are cache
consistency and data integrity. Preserving both can have adverse effects on
performance thus thwarting the above estimation. The following paragraph deals
with data integrity as guaranteed by the isolation property in ACID.

When two or more transactions are run concurrently, race conditions on shared
data are bound to occur. Race conditions on the other hand, may cause data
conflicts which in turn can lead to inconsistent data. The possible conflicts
are:

\begin{itemize}
    \item write-write
    \item write-read
    \item read-write
\end{itemize}

\todo[inline]{explain conflicts}
\todo[inline]{explain serializability}

\paragraph{Transaction Models}

\todo[inline]{distinguish software tx vs. transactional memory}

\section{Concurrency Control Protocols}

\subsection{Locking}

\subsection{Multiversioning}

\subsection{Serializable MVCC}

\section{Key-Value Stores for NVRAM}

\paragraph{Summary}

\begin{itemize}
    \item KVS are vital database technology; esp. distributed but beyond scope
    \item performance can be increased through in-memory operation + concurrency
    \item a widely-adopted concurrency control is MVCC; but most impl. non-ser.
    \item KVS for NVRAM have shown some potential over traditional KVS
    \item recent KVS for NVRAM all non-ser. => leverage boost to provide ser.
\end{itemize}
