After outlining goals and preconditions in the previous section, this section
presents the architecture of the KVS. It covers all aspects, except crash
consistency and concurrency control which are dealt with in more detail in
subsequent sections.

The KVS is designed for multi-core architectures and relies on both volatile and
non-volatile memory attached to the system memory interface. In order to take
advantage of both types of memory, the KVS is designed as a two-level store
which only updates NVRAM when a transaction commits. Consistency across crashes
is ensured with existing hardware primitives and upcoming platform features.
Concurrent transactions are controlled with a serializable variant of SI. The
reasoning behind these design decisions is further elaborated below.

\subsection{System Architecture}

Designing a runtime-critical software such as databases not only involves
knowledge about expected workloads but also about the underlying hardware. While
workloads have been discussed earlier, this section describes the system
architecture of the intended KVS.

\paragraph{Single-Node}

First and foremost, the KVS is designed for a single-nodes. Even though
distributed databases are fairly common, there seems to be no apparent reason
for them to reveal any more insight on leveraging NVRAM for concurrency. Also
distributed systems involve much more complex mechanisms such as consensus among
distributed transactions, all of which are beyond the scope of this work.
However, future work should investigate whether the conclusions of this work
also hold for distributed databases.

\paragraph{Multi-Core Processors}

In order to achieve scalable transaction throughput through concurrency, the
target system is a multi-core architecture. That means, the system features one
or more processors with multiple cores, where each core may support multiple
hardware threads. On such a system, each transaction is executed in the context
of a thread which is scheduled and assigned to a processor core by the operating
system. [Should future work address many-cores? Could memory bandwidth (bus
contention) become a problem there?] In order to coordinate their work,
processors usually communicate via some form of chip interconnect. This work
makes no assumptions concerning the nature of such networks or their topologies.

\paragraph{Hybrid Memory Architecture}

Recent research shows that on traditional hardware it is advisable to continue
integrating volatile RAM together with NVRAM. The reason is that not all data is
meant to be durable which is especially true for NVRAM where crash consistency
is linked with considerable overhead. Manufacturing NVRAM is still challenging,
especially in terms of access latency and endurance, but it is expected that
these issues will be resolved in the near future. Therefore, in an effort to
combine the benefits of both technologies, the memory subsystem is required to
feature both volatile RAM and NVRAM. [<-- Move to top of segment?] In accordance
with recent research it is assumed that both kinds of memory can be access
through the same memory interface. This work assumes a shared memory
architecture. That is, processors may one or more private cache levels but main
memory is accessible to all processors. Conceptually, cache coherence is not
required but has the advantage that less programming effort is spent on
coordinating concurrent access to shared data.

The KVS is designed to exclusively reside in main memory. All data that is not
required across restarts is stored in volatile RAM, whereas all other data are
stored in NVRAM. Multiple recent works have demonstrated that NVRAM can be used
to build MMDB without conventional non-volatile storage such as hard drives. As
a result, ensuring recovery, which has always been an inherent bottleneck of
MMDB, can be eliminated. In addition, near instantaneous restarts become
feasible. As a consequence, conventional storage is not part of the concept for
this KVS. While such components may very well be present in a system, they are
never used to store any data of the KVS other than its binaries. This way, data
access incurs no I/O and restarts do not have to fetch data from slower storage
devices. In return, candidate systems must provide sufficient NVRAM capacity to
hold the entire database.

A disadvantage of this approach is that the size of the database is strictly
limited to the amount of available NVRAM. In contrast, many MMDB allow for
larger amounts of data by keeping frequently used data in memory, while others
are moved to another medium. However, main memory capacities have been steadily
growing and NVRAM capacities are projected to have at least twice the capacity
of DRAM. Another drawback is recoverability in case of device failures. Disk
storage not only scales better in terms of capacity, it can also be used to
employ redundancy through RAID, for instance. With NVRAM, both capacity and
scalability are lower, so employing redundancy could be a problem. Without
redundant data, a single failed device may incur expensive data loss. This issue
could be investigated in future work.

\subsection{Key-Value Store}

\paragraph{Two-Level Store}

\paragraph{Multiversioning}

\paragraph{Structures}
