The KVS is designed for multi-core architectures and relies on both volatile and
non-volatile memory attached to the system memory interface. In order to take
advantage of both types of memory, the KVS is designed as a two-level store
which only updates NVRAM when a transaction commits. Consistency across crashes
is ensured with existing hardware primitives and upcoming platform features.
Concurrent transactions are controlled by a serializable variant of SI.
Background on these design decisions is given below.

Designing a runtime-critical software such as databases not only involves
knowledge about expected workloads but also about the underlying computing
device. While workloads have been discussed earlier, this section describes the
system architecture of the intended KVS.

\subsubsection{Concurrency}

The KVS is designed for a single-node architecture. Even though distributed
databases are fairly common, there seems to be no apparent reason for them to
reveal any more insight on leveraging NVRAM for concurrency. Also distributed
systems involve much more complex mechanisms such as consensus among distributed
transactions, all of which are beyond the scope of this work. However, future
work should investigate whether the conclusions of this work also hold for
distributed databases.

In order to achieve scalable transaction throughput through concurrency, the
target system is a multi-core architecture. That means, the system features one
or more processors with multiple cores, where each core may support multiple
hardware threads. On such a system, each transaction is executed in the context
of a thread which is scheduled and assigned to a processor core by the operating
system. Processors usually coordinate their work by communicating via some form
of chip interconnect. In order to preserve generality, this work makes no
assumptions concerning the nature of such interconnect networks.

\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.5]{figures/drafts/concept-sys-cpu.pdf}
    \caption{}
    \label{fig:concept-sys-cpu}
\end{figure}

\subsubsection{Memory Architecture}

Recent research shows that on traditional hardware it is advisable to continue
integrating volatile RAM together with NVRAM. The reason is that not all data is
meant to be durable which is especially true for NVRAM where crash consistency
is linked with considerable overhead. Manufacturing NVRAM is still challenging,
especially in terms of access latency and endurance, but it is expected that
these issues will be resolved in the near future. Therefore, in an effort to
combine the benefits of both technologies, the memory subsystem is required to
feature both volatile RAM and NVRAM. In accordance with recent research it is
assumed that both kinds of memory can be accessed through the same memory
interface. This work assumes a shared memory architecture. That is, processors
may have one or more private cache levels but main memory is accessible to all
processors. Conceptually, cache coherence is not required but has the advantage
that less effort is spent on coordinating concurrent access to shared data.

The KVS is designed to exclusively reside in main memory. All data that is not
required across restarts is stored in volatile RAM, whereas all other data are
stored in NVRAM. Multiple recent works have demonstrated that NVRAM can be used
to build MMDB without conventional non-volatile storage such as hard drives. As
a result, ensuring recovery, which has always been an inherent bottleneck of
MMDB, can be eliminated. In addition, near-instantaneous restarts become
feasible. As a consequence, conventional storage is not part of the concept for
this KVS. While such components may very well be present in a system, they are
never used to store any data of the KVS other than its binaries. This way, data
access incurs no I/O and restarts do not have to fetch data from slower storage
devices. In return, candidate systems must provide sufficient NVRAM capacity to
hold the entire database.

\begin{figure}[!ht]
    \centering
    \includegraphics[scale=0.5]{figures/drafts/concept-sys-mem.pdf}
    \caption{}
    \label{fig:concept-sys-mem}
\end{figure}

A disadvantage of this approach is that the size of the database is bounded by
the amount of available NVRAM. In contrast, MMDB usually allow for larger data
sets by keeping frequently used data in memory, while others are moved to slower
mass storage media. However, main memory capacities have been steadily growing
and NVRAM capacities are projected to have at least twice the capacity of DRAM.
Another drawback is recoverability in case of device failures. Mass storage not
only scales better in terms of capacity, but it also supports redundancy through
RAID, for instance. With NVRAM, both capacity and scalability are lower, so
employing information redundancy may be prohibitively expensive. Without such
measures of fault tolerance, however, a single failed NVRAM module may lead to
permanent data loss. This issue is not tackled in this thesis and is therefore
left for future work.
