This section presents the software architecture of Midas. After a brief
overview, focus is set on NVRAM management, durable data structures, and
serializable MVCC.

\todo[inline]{impl-arch: describe architecture of the store (layers, components)}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.75]{figures/impl/arch.pdf}
    \caption{System architecture layers of Midas.}
    \label{fig:impl-arch}
\end{figure}

\subsection{NVRAM Management}
\label{ch:impl-nvram}

As explained in Chapter \ref{ch:nvram} there are several challenges to the
integration of NVRAM into current systems. Among these are the following:

\begin{itemize}
    \item Accessing NVRAM
    \item Programming against NVRAM
    \begin{itemize}
        \item Separation of volatile from non-volatile data
        \item Recovery of non-volatile objects after restart
        \item Preserving consistency across restarts
    \end{itemize}
\end{itemize}

In the past, several approaches have been discussed to address these challenges.
Recent research, however, shows rising interest in PMDK (formerly known as
NVML). PMDK is a set of both C and C++ libraries and appears to be the first
practical holistic approach to managing NVRAM. Therefore, this work uses PMDK to
implement NVRAM management.

\subsubsection{NVRAM Access}

In PMDK, NVRAM is accessed via ordinary filesystems such as \code{ext4} or
\code{tmpfs}. That way, NVRAM can be mapped into a process' address space via
plain files. Using a kernel feature called \emph{Direct Access} (also DAX)
filesystems can bypass the operating system's page cache. This enables true load and store semantics. In addition, swapping is disabled for the
respective memory region.

\subsubsection{Programming Model}

Apart from its core, the essential part of PMDK used in this work is called
\code{pmemobj}. With it, a persistent object pool holds all data that are meant
to be durable. Memory inside the object pool is managed by a designated memory
allocator. For each object which is meant to be durable, it allocates the
required amount of memory and registers the resulting object in the object pool.
This way, all objects can be recovered on restart. From a programmer
perspective, objects are managed in a graph rooted in the object pool. Using
this graph, which is recovered after restart, the programmer can access all
previously durable objects.

\paragraph{Durable Data}

In order to separate volatile from non-volatile objects, there are templated
wrapper classes to manage integral values and dynamically allocated objects:

\begin{itemize}
    \item \code{pmdk::p<T>} for durable integral values
    \item \code{pmdk::persistent\_ptr<T>} for pointers to durable objects
\end{itemize}

\paragraph{Durable Objects \& Pointers}

A \code{persistent\_ptr} consists of a non-volatile unique object id and a
virtual memory address within the object pool. The virtual address is volatile
because it is not valid across restarts. Therefore, the object id is mapped to a
relative memory address within the object pool. Using the object id, the virtual
memory address of an object can be computed from its relative address to the
pool base on every restart. This is necessary, because in most operating systems
virtual address space layout is different for each session. When creating an
object, the function \code{pmdk::make\_persistent<T>()} is used. The lifetime of
a durable object spans across scopes and restarts. In order to deallocate an
object, the function \code{pmdk::delete\_persistent<T>()} must be used.

\paragraph{Preserving Consistency}

In order to ensure consistency across crashes in NVRAM, stores must be flushed
immediately. In PMDK, this can be done explicitly for selected memory regions or
implicitly by using a so-called transaction. A transaction receives the current
object pool and a functor. Each persistent property or pointer that is modified
by the functor, registers itself with the transaction. When the transaction
commits, all registered objects are made durable in NVRAM. A transaction commits
when its functor completes without errors. In the example below a durable object
of type \code{T} is created inside a pool which has a graph root of type
\code{Root} (see Listing \ref{lst:pmdk-tx}). Assume the global variable
\code{objCount} is supposed to reflect the correct number of durable objects.
For that purpose, both creating of objects and incrementing the counter are
consolidated in a transaction to form a single memory update.

\begin{figure}[h!]
\begin{lstlisting}
#include "libpmemobj++/persistent_ptr.hpp"
#include "libpmemobj++/transaction.hpp"
#include "libpmemobj++/pool.hpp"
namespace pmdk = pmem::obj;

pmdk::p<size_t> objCount = 0;

template <class T, class Root>
pmdk::persistent_ptr<T> create(pmdk::pool<Root> pop)
{
    pmdk::persistent_ptr<T> obj = nullptr;

    // Consolidate updates in transaction
    pmdk::transaction::exec_tx(pop, [&, this](){
         obj = pmdk::make_persistent<T>();
         objCount = objCount + 1;
    });

    // At this point, all changes to NVM are either completely durable or absent
    return obj;
}
\end{lstlisting}
\caption{Consistent updates to NVM using PMDK transactions.}
\label{lst:pmdk-tx}
\end{figure}

Even though object creation is always transactional in PMDK, initialization is
not. Instead, the memory of an object is only nulled. As a result, each class
intended for durability must be \emph{trivially default constructible}, which
means that a compiler-generated default constructor must be sufficient to
initialize an instance of the class. Otherwise, the programmer has to use custom
initialization procedures.

Internally, PMDK uses largely the same mechanism for consistency as described in
Chapter \ref{ch:nvram-consistency}. That means, modified data are flushed from
memory order buffers and caches. In some situations, non-temporal writes are
used which make use of write combine buffers. When it comes to flushing
write-pending queues inside the memory controller, PMDK relies on ADR.

% =============================================================================
% =============================================================================
% =============================================================================

\subsection{Data Structures}
\label{ch:impl-data}

The implementation of Midas relies on several classic data structures, such as
arrays, lists, and hash maps. Since Midas consists of two separate volatility
domains, each domain requires its own dedicated data structures. This section
outlines the types of data structures employed in Midas. Selected use cases are
given in the next section (see Chapter~\ref{ch:impl-mvcc}).

\subsubsection{Volatile Data Structures}

In terms of data structures, the volatile part of Midas consists of a
transaction table and transaction control blocks. These data structures are
mostly composed of standard library containers, since modifications need not be
durable.

The transaction table should provide fast
lookup capabilities and is therefore implemented as a hash table. However, it is
also a shared resource that must be synchronized. In order to prevent a
bottleneck, the concurrent hash table implementation \emph{libcuckoo} is used
\cite{fan2013memc3, li2014algorithmic, libcuckoo2018home}.

Transaction control blocks, on the other hand, only share atomic timestamps
while the remaining read and write sets are thread local. Read sets are plain
vectors of versions accessed for reading. In contrast, write sets are
implemented as hash maps because a transaction might update an item multiple
times and looking up a previously written item is faster than repeatedly
performing a linear search on its history.

\subsubsection{Non-Volatile Data Structures}

In the non-volatile domain of Midas, data structures must be NVRAM-aware. That
means, that data structures must be recoverable from a durable state when Midas
starts and also ensure that updates to NVRAM do not inflict inconsistencies.
Durable data structures in Midas are the index and the version histories
contained therein.

The index is used to lookup version histories, thus it is implemented as a hash
table. Histories, on the other hand, are implemented as linked lists because
they are accessed in linear order. Lacking general-purpose container libraries
for NVRAM, both non-volatile data structures are developed from scratch.

\paragraph{Doubly-Linked List}

The doubly-linked list is implemented in the template class \code{NVList}. Its
attributes consist of a pointer to first element, a pointer to the last element,
and an element counter. All these attributes must be durable in order to recover
the list after a restart. Therefore, they are declared as persistent pointers or
properties in terms of PMDK. The API of \code{NVList} is closely related to the
C++ standard library containers. It also provides iterator facilities for
traversal.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.66]{figures/impl/list.pdf}
    \caption{Class diagram for the class \code{NVList}}
    \label{fig:impl-list}
\end{figure}

An important aspect of implementing durable data structures is to preserve
consistency. This is done by consolidating related allocations and operations on
durable objects in a transaction as shown in Chapter \ref{ch:impl-nvram}.

\begin{figure}[h!]
\begin{lstlisting}
void push_back(const elem_type& elem)
{
    pmdk::transaction::exec_tx(pool, [&,this](){
        auto new_node = pmdk::make_persistent<node>();
        new_node->mValue = elem;
        append(new_node);
        mSize = mSize + 1;
    });
}
\end{lstlisting}
\caption{Implementation of \code{push\_back()} as an example for transactional updates to NVRAM}
\label{lst:impl-list-tx}
\end{figure}

An additional feature of \code{NVList} is a zero-copy mechanism for migrating
individual list nodes between different lists. This is useful when nodes from a
single list must be scattered to several other lists as is done when rehashing a
hash table. The feature is provided by the functions \code{push\_back\_from()}
and \code{push\_front\_from()}.

\paragraph{Hash Table}

The hash table is implemented as a template class called \code{NVHashmap}.
Essentially, the table consists of a single persistent array that is reallocated
as needed. Each cell in the index is called slot or bucket. As with
\code{NVList}, the API of \code{NVHashmap} is closely aligned to the C++
standard library. Also, the class employs a policy-based template design which
allows changing its behaviour through template parameters.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.66]{figures/impl/map.pdf}
    \caption{Class diagram for the class \code{NVHashmap}}
    \label{fig:impl-map}
\end{figure}

There are three important aspects to the design of hash tables: the hash
function itself, collision handling, and growth policy. The hash function used
in Midas is a variant of the hash function used in the string library of Java
\cite{javadoc2018hashcode}, which is a polynomial of prime powers and character
bytes as coefficients. The final access index is computed modulo of the current
table size.

When disjoint keys result in equal hashes a collision occurs. In the case of
Midas, collisions are handled by \emph{chaining}. With chaining, each slot in
the table is a linked list and keys are always stored in pairs with their mapped
value. When hashing a key, the corresponding bucket is searched for a pair with
a matching key. If no such pair is found, then the given pair can be inserted.
As a result, each bucket only contains pairs with conflicting key hashes. Both
the collision lists and the pairs are durable.

Because searching long buckets increases access time, the table is expanded
regularly. More precisely, expansion occurs when the maximum load factor is
exceeded. The load factor is defined as the ratio of the number of pairs and the
number of buckets. The maximum load factor is set to $0.75$. In order to
amortize the cost of reallocations, the table size is doubled on each expansion.
After an expansion, all pairs are rehashed into the new table. This is where the
zero-copy list node migration of \code{NVList} is used. Parameters such as the
maximum load factor or the growth factor can be adjusted using the policy-based
template design.

\todo[inline]{impl: elaborate on volatile/non-volatile key dissonance (optional)}

% * policy-based design for
%     * hashing volatile and non-volatile keys
%         * user does not know about a different represent. of obj. in pmem
%         * volatile keys must have equal hashes with non-volatile counterparts
%         * for safety many hash functions are not equal across restarts
%             * => cannot find pairs after restart
%             * => a) use fixed hash function (impl. from JDK)
%             * => b) rehash entire table (expensive!)

% =============================================================================
% =============================================================================
% =============================================================================

\subsection{Serializable MVCC}
\label{ch:impl-mvcc}

\subsubsection{Transactions}

\subsubsection{Versioning}
\paragraph{Versions}
\paragraph{Histories}
\paragraph{Visibility}

\subsubsection{Conflicts}
