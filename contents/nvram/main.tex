\chapter{Non-Volatile RAM}
\label{ch:nvram}

Popular non-volatile storage technologies such as HDD or SSD can only be
operated as block devices and incur high access latencies compared to volatile
DRAM. This led to the development of non-volatile analogies of DRAM, which
however failed to see wide adoption. One reason was that these devices were
either block-oriented or required additional peripherals such as batteries.

Recent research however, suggests that fast and byte-addressable NVM will be
available in the near future. Based on its projected characteristics, this new
class of memory is also referred to as NVRAM.

\todo[inline]{Short chapter overview}

\paragraph{Terminology}

As of this writing there is no consensus as to how byte-addressable non-volatile
memory should be referred to. This thesis exclusively uses term NVRAM. There are
two reasons for this decision. For one, alternative terms such as BPRAM or PM
suggest that non-volatile memory is also persistent which however, may not
always be correct \todo{proof?}. Another reason is that some terms such as SCM,
NVM and PM may not reflect the property of bytewise addressing which is central
to these technologies. NVRAM on the other hand, explicitly denotes all of the
desired properties.

\section{Applications}

There are numerous examples for applications of NVRAM. While earlier works often
considered NVRAM as a means to improve fault tolerance, recent research suggests
a broader range of applications. This development is especially fuelled by
recent advances in the manufacture of standalone NVRAM instead of battery-backed
DRAM. In practice, application scenarios also include assumptions on the
properties of NVRAM and the surrounding system architecture. Such issues are
covered in later sections.

As pointed out earlier, a well-known use case of NVRAM is to increase fault
tolerance towards crashes. The goal is to retain main memory content even in
case of a crash, for instance by an abrupt power loss \cite{molina1992main}.
This way, critical data such as logs of file systems (also journals) or
databases remain durable and can be used to recover and even complete unfinished
operations such as making a transaction durable \cite{liskov1991replication,
chen1996rio}. Furthermore, NVRAM can be used to create durable disk caches,
hence shrinking the window in which disk IO is vulnerable to crashes
\cite{chen1996rio, wu1994envy}. In the past, such solutions relied on
battery-backed DRAM or SRAM. This was subject to criticism as batteries only
have a limited charge to ensure durability. Also batteries degrade over time and
need to be maintained to prevent unexpected failure \cite{molina1992main}.
Therefore, modern NVRAM solutions which no longer require peripherals are a
welcome improvement in this area.

A significant amount of research on NVRAM is dedicated to mitigating the IO
bottleneck imposed by traditional disk storage. One way to do so is to defer
disk IO via durable disk caches \cite{chen1996rio, wu1994envy}. When an object
on disk is requested it is moved to the disk cache. Once an object is cached it
may be read or modified with accessing the underlying disk. In theory,
write-back is only required when there is not enough space for an incoming cache
item. This way, frequently used objects incur no latency penalty through disk
IO. Many operating systems, such as Linux or BSD implement such mechanisms where
it is usually referred to as page buffer \todo{quote?}. The difference is that
conventional page buffers are volatile and need to be flushed at some point
which requires careful resource management.

Another approach is to treat NVRAM as an equivalent to traditional disk storage.
Early works which were strongly influenced by the lack of high-capacity NVRAM
proposed hybrid storage systems where disk storage was used in conjunction with
NVRAM \cite{wang2002conquest, miller2001hermes}. These works have very similar
assignment policies in that they only store small files such as  metadata or
libraries in NVRAM whereas larger files remain on disk. While this does not
remove disk access as a common bottleneck it certainly alleviates latency for
some frequently accessed files. In this regard, NVRAM-complemented disk storage
systems are similar to those with NVRAM disk caches.

A more rigorous implementation of the paradigm of NVRAM-assisted mass storage is
to remove all traditional storage and rely solely on NVRAM. A prominent use case
for this architecture are MMDB. Conventional MMDB keep all their data in
volatile main memory and only use disks for recovery in case of crash. Recovery
measures such as logging have been a long-standing issue with MMDB as they incur
expensive disk IO, thus limiting the overall throughput. With NVRAM, disk IO can
be eliminated allowing for faster logging and recovery using the main memory
bandwidth. This concept is especially promising as some upcoming variants of
NVRAM are projected to feature larger capacities than conventional DRAM
\todo{quote!}. For this reason, recent research has presented NVRAM-aware
designs for MMDB ranging from complex database systems \cite{oukid2015instant,
schwalb2016hyrise} to key-value stores \cite{bailey2013exploring, zhou2016nvht,
wu2016nvmcached}. Another notable example is \emph{Machine}, a novel computer
architecture which comprises a cluster of special purpose processors and large
amounts of NVRAM \cite{courtland2016can}.

\paragraph{Further Applications}

It was shown in various works that advantages can be gained by using NVRAM.
Still, most proposals assume the presence volatile RAM in addition to NVRAM
\cite{oukid2017data}. The reason behind this assumption is that not all parts of
memory are intended to be durable. This is true for regions capturing machine
state or security-relevant data. Nonetheless, recent research suggests that
systems exclusively based on NVRAM can be built \cite{narayanan2012whole}.
Clearly, such an architecture would have severe consequences for both operating
systems and applications \cite{bailey2011operating}. For example, operating
system processes would remain in memory even if terminated. On the one hand,
this could significantly accelerate the procedure of invoking a process. On the
other hand, all data belonging to a process' address space would be durable even
if they were corrupted by a crash. Other issues are concerned about memory
management, device drivers, and vital information. An early prototype of such a
system is currently in development \cite{courtland2016can}. This topic however,
is beyond the scope of this work and is not subject to further discussion.

In a more recent effort to aid machine learning, it has been proposed to
implement artificial neural networks by means of NVRAM
\cite{fumarola2016accelerating}. ANN perform a weighted sum over all inputs
while an activation function acts as a classifier. For this to work, ANN need to
be trained by properly adjusting the scalar weights. It has been suggested that
this process could be performed directly in NVRAM where updated weights would be
durable without the need for write-back.

\section{Technologies}

In the past, there have been multiple attempts to produce non-volatile
equivalents of main memory. One way is to emulate non-volatility by providing
backup power supplies or combining volatile DRAM and conventional non-volatile
storage in a single module. Another promising approach is to develop alternative
memory techniques that provide the features of NVRAM. This section presents
notable developments in the field of NVRAM.

% \paragraph{Early Approaches}
%
% Initially, the intention was to make systems more tolerant to failures, although
% opportunities for storage systems were also discussed \cite{molina1992main,
% wang2002conquest}. The main issue with DRAM is that, in order to retain its
% data, it needs to refresh its cells which requires a power supply. Therefore,
% early non-volatile main memories were equipped with batteries or UPS which
% allowed to hold information for a limited time in case of a power failure.
% Notable examples for systems using battery-backed DRAM are the file systems
% \emph{Harp} \cite{liskov1991replication} and \emph{Conquest}
% \cite{wang2002conquest} as well as the file cache \emph{Rio} \cite{chen1996rio}.
%
% In another approach, researchers used battery-backed SRAM as a write buffer
% which is flushed to an interconnected flash memory when full or in case of a
% power failure \cite{wu1994envy}. By limiting access to the SRAM, the
% non-volatile yet slower flash device is effectively shadowed. Still, since flash
% operates in block mode, the byte-addressable nature of SRAM cannot be exploited
% in this setup. This is an early example of hybrid memory solutions for fast mass
% storage. However, backup power supplies have also been subject to criticism.
% Arguments are that batteries are not inherently reliable and introduce
% additional maintenance overhead \cite{molina1992main}. Therefore experiments
% were conducted, where flash memory was directly attached to the memory interface
% \cite{shi2010write}. Similar ideas were later consolidated in the JEDEC NVDIMM
% specification, which defines several configurations for DIMMs consisting of
% flash memory and DRAM \cite{oe2016feasibility, huang2014design}.
%
% % This marks a shift in the development of NVRAM as reliability becomes second
% % to fast high-capacity storage.
%
% \paragraph{Modern Approaches} % TODO modern approaches
%
% Early approaches for practical NVRAM were focused on making volatile DRAM retain its information across power outages. There are however promising alternatives such as PCM, MRAM or RRAM which are both byte-addressable and non-volatile by design. Although their underlying principles have been known for a while, further research was required to reach practical designs for manufacturing. Recent research suggests that these NVM technologies will see broad availability in the near future \todo{cite}.

% technologies
    % PCM (also PRAM)
    %     phase-change memory
    %     based on properties of chalcogenide glasses
    %     discovered in 1955
    %     first prototype in 1969
    % STT-MRAM (also ST[T]-[M]RAM)
    %     advanced type of MRAM
    %         magnetoresistive RAM
    %         similar to magnetic core memory (1955)
    %         GMR effect discovered in 1984
    %         developed since 1995 (Motorola)
    %     spin-transfer torque proposed in 1996
    % RRAM (also ReRam)
    %     resistive RAM
    %     resistive switching discovered in 1967
    %     disputed to be a memristor
    % memristors
    %     ???
    % FeRAM

% density: DRAM < STT-RAM < PCM (higher is better)
% endurance: PCM < STT-RAM < DRAM (higher is better)
% latency: DRAM <= STT-RAM < PCM (lower is better)
% dypower: STT-RAM < DRAM < PCM (lower is better)

\section{Challenges}

Despite the conceivable advantages of NVRAM, there are also challenges to be
addressed. Although most issues are of practical nature there also are
conceptual concerns.

\paragraph{Unintended Durability}

The key feature of NVRAM is to retain its data across restarts. However, not all
data are necessarily intended to be durable. Notable examples include transient,
confidential and corrupt data. The former comprises data which may not be valid
after a system restart, as is the case with data related to machine or device
state.

Other data such as passwords, encryption keys or decrypted data are usually
confidential and are thus not intended to be durable. Also, it has been shown
that even volatile RAM holds its charge long enough so that a module can be
moved to an attacker's machine \cite{halderman2008lest}. By cooling the module,
capacitor discharge can be slowed so that it can be moved to another machine
where its content may be read and parsed. Despite being countered with hardware
scramblers, researchers still managed to apply variations of the technique and obtain vital information \cite{yitbarek2017cold}. Such attacks
would be trivial on NVRAM, as durability is its primary feature
\cite{bailey2011operating}. Of course, confidential data could be overwritten
with zeros after usage, but there is always a possibility that a crash might
prevent such clean up tasks from completing. That said, sensitive data should at
all times remain in volatile memory and be nulled after use.

When an operating system or application behaves in erratic fashion or crashes it
may produce corrupt data in memory. Unless memory is cleared or rewritten,
systems incorporating NVRAM could face durable memory corruptions. The latter
may lead to an unstable system producing even more corrupted data. Although the
same is true for conventional non-volatile memory it is still operated through
the operating system in terms of an API and volatile page buffers. NVRAM on the
other hand is expected to be connected to the memory bus, enabling unbuffered
access through virtual memory addresses. This makes NVRAM vulnerable to stray
writes \cite{condit2009better, oukid2017data}. However, it is suggested that,
compared to disk storage, stray writes do not occur significantly more
often in NVRAM \cite{chen1996rio}.

\paragraph{Memory Management}

NVRAM is a new type of memory that can also be used as durable mass storage. In
order to benefit from this new technology, both platforms and operating systems
need to find ways to efficiently manage it. There are several issues to be
addressed in this area.

% Memory Interface

An important aspect in managing NVRAM is the memory interface. Recent research
suggests that NVRAM will be attached to the system memory bus
\cite{intel2017nvdimm, oukid2017data}. An advantage of this approach is better
latencies compared to the alternative IO bus. Another reason is that a previous
attempt to produce NVRAM, also known as NVDIMM, modules have also been
integrated this way \cite{dulloor2014system}. Drawbacks include shared bandwidth
with volatile RAM and fixed amounts of module slots \cite{condit2009better}.

It further suggested that, in accordance with NVDIMM, NVRAM modules will be
accessed through special device drivers \cite{oukid2017data}. Instead of mapping
the device's address space into virtual memory, there is a consensus that
specialized file systems will be used to manage NVRAM. Reasons are that a direct
mapping would make it difficult to distinguish non-volatile from volatile memory
and address space layout randomization would render pointers to NVRAM useless
after a restart.

File systems provide a well-known and suitable abstraction for non-volatile
storage. In order to enable regular memory access in a load-store manner,
individual files can be mapped into virtual memory. Still, traditional file
systems are not directly well-suited for use with NVRAM. One reason is that most
operating systems provide a page cache which is used by file systems to defer
expensive disk IO. In the case of NVRAM, this leads to unnecessary copies to
volatile RAM, thus mitigating its benefits. Also traditional file systems are
usually designed for block-oriented devices which may no longer be the best
option. Therefore, several NVRAM-aware file systems such as \emph{pmfs},
\emph{bpfs}, and \emph{scmfs} have been proposed \cite{condit2009better,
wu2011scmfs, dulloor2014system}. A key feature is a zero-copy mechanism by
circumventing page caches. This enables true store-load semantics for NVRAM when
mapping files into virtual memory. Other aspects include the attempt to leverage
the byte-addressable nature of NVRAM and crash-related consistency issues.

% Other more specialized file systems include aerie and scmcfs
% \cite{volos2014aerie, tao2016nvmcfs}.

% Programming Model

Still, programmers need a mechanism to distinguish non-volatile memory from
volatile memory. This implies some form of a dual memory management. Notable
problems include volatile memory mappings of NVRAM and both efficient and robust
memory allocators. Therefore, many authors have proposed designated allocators
and pointer types for use with NVRAM \cite{wu2011scmfs, moraru2013consistent,
oukid2014sofort, schwalb2015nvm_malloc}.

\paragraph{Consistency}

A notorious problem with NVRAM is consistency in case of crashes
\cite{condit2009better, dulloor2014system, oukid2017data}. Due to the complex
nature of this subject further discussion is deferred to the next section.

\section{Preserving Consistency}

As pointed out earlier, the consistency of data stored in NVRAM is vulnerable to
crashes or power failures. Since NVRAM is directly attached to the processor
memory interface, there is no need to use techniques such as DMA to transfer a
modified page to external storage. This also means that a memory operation
solely relies on the CPU which usually gives no confirmation when that operation
completes. In this context, there are two major issues that threaten the
consistency of data written to NVRAM, namely out-of-order execution and deferred
write-back.

\paragraph{Out-Of-Order Execution}

In an attempt to optimize instruction throughput, processors may reorder
instructions at runtime. This enables processors to optimize resource
utilization and hide latencies of time-consuming instructions. However, only
reorderings that do not violate data dependencies between instructions are
possible. While processors do prevent such conflicts, there are dependencies
that cannot be observed. For example, in order to mark a chunk of data as
durable in NVRAM, one might store a designated flag immediately after the
operation completed. With out-of-order execution it is possible that the flag
is written before the payload. This can lead to severe inconsistencies
especially when a crash prevents the chunk from being written.

A common method to counter this issue is to enforce memory order with memory
barriers (also fences) \cite{dulloor2014system, schwalb2016hyrise,
oukid2017data}. A memory barrier prevents the CPU from proceeding until all
prior memory operations have completed. Although a barrier does not directly
order its preceding instructions, it can be used to impose an order on separate
sequences of instructions. An example for a memory barrier is \code{sfence} on
x86 architectures. While this approach solves the initial problem, it has a
notable drawback. Barriers defeat the purpose of out-of-order execution. As a
result, CPU pipelines are likely to stall, hence reducing resource utilization.
Therefore, barriers can have significant impact on runtime performance, unless
used judiciously. With \emph{epoch barriers} a similar approach has been
proposed to address both order and durability issues when writing to NVRAM
\cite{condit2009better}.

\paragraph{Deferred Write-Back}

In many modern processor architectures store operations may not  be immediately
lead to an update in main memory. This behaviour can be caused by intermediary
buffers such as memory order buffers, caches, and memory controller buffers.
While their individual purpose may vary, they all defer memory write-back
operations. This is a known vulnerability for consistency in NVRAM as the
mentioned buffers are volatile and deferred stores may be lost when power fails
\cite{condit2009better, oukid2017data}. In order to preserve consistency, it is
necessary to force write-back in all of these cases.

% memory order buffers

In conjunction with instruction scheduling and cache coherency protocols a
memory order buffer may be present. It holds all loads and stores, with the
exception of non-temporal operations. In order to prevent a deferred write-back
through memory order buffers, their store buffers must be flushed. On x86
architectures this can be achieved with a store fence operation such as
\code{sfence}. Since memory barriers are already used for enforcing program
order, flushing store buffers is a desirable side effect and incurs no overhead.

% caches

Processor caches help avoid access latencies and reduce memory bus traffic for
frequently used data. A possible exception are non-temporal stores and data
chunks marked as uncacheable. As well as memory order buffers caches are
volatile, so an abrupt power failure may lead to lost updates. The issue with
this is not that updates are lost but that it is unclear which updates are lost
if any. The reason for this circumstance is the cache eviction policy trying to
compensate for typically narrow cache volume. Depending on policy, cache
content, and system load a modified chunk may or may not be flushed to main
memory. An example of an application scenario where such behaviour is
unacceptable is transactions. Imagine an updating transaction $t1$ that commits
but is not evicted from cache. Then a transaction $t2$ based on the result of
$t1$ commits and gets evicted from cache. If the system crashes at this point,
$t2$'s result will be durable while $t1$'s initial update is lost.

% T1: r(A) w(A) c*   -- Cache ---------------------- (crash)
% T2: -------------- r(A) w(B) c -- Cache -- RAM --- (crash)

An approach to prevent such inconsistencies is to disable caching for selected
memory regions but that could introduce considerable overhead for frequently
used data. A more popular approach is to evict cache lines programmatically
whenever necessary \cite{condit2009better, dulloor2014system, oukid2017data}. On
x86 architectures this can be done with the \code{clflush} or \code{clwb}
instructions. However, the problem with a simple cache line flush such as
\code{clflush} is that making a cache line durable may not always mean that is
should be evicted. In this regared, \code{clwb} compensates for this matter by
retaining the designated cache line \cite{kolli2016high}.

% memory controller queues

Once a cache line is flushed, it is propagated to the memory controller where it
is buffered in a write-back queue before being written onto the device. Again,
the problem is that such a buffer is usually volatile. This means that a power
failure could lead to lost updates to NVRAM. Even though residual power in DRAM
has been shown to be substantial, there is no reliable way to ensure a full
buffer flush \cite{halderman2008lest}. This circumstance has given rise to many
discussions in the past \cite{condit2009better, dulloor2014system,
kolli2016high}. Some authors proposed a designated instruction for flushing
write-back queues. An example is the meanwhile deprecated \code{pcommit},
formerly known as \code{pm\_wbarrier} \cite{dulloor2014system, oukid2015instant,
schwalb2015nvm_malloc, volos2017whisper}. Others have developed more general
mechanisms for preserving consistency in NVRAM that also address this issue
\cite{condit2009better, pelley2014memory}. The current state in this regard is
that platforms must provide Asynchronous DRAM Refresh which ensures a queue
flush whenever a power failure is detected \cite{volos2017whisper}. It works by
exploiting the fact that even in case of a power failure there is sufficient
time and power to flush the write buffers of all memory controllers. For this to
work, the power supply unit has to detect a power failure and issue a signal to
the memory controllers.

% \todo[inline]{epoch barriers (condit2009better)?}
% \todo[inline]{strand consistency (pelley2014memory)?}
% \todo[inline]{whole system persistence (narayanan2014whole)?}
