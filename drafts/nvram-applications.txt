# NVRAM

## Applications

There are numerous examples for applications of NVRAM. While earlier works often considered NVRAM as a means to improve fault tolerance, recent research suggests a broader range of applications. This development is especially fuelled by recent advances in the manufacture of standalone NVRAM instead of battery-backed DRAM. In practice, application scenarios also include assumptions on the properties of NVRAM and the surrounding system architecture. Such issues are covered in later sections.

As pointed out earlier, a well-known use case of NVRAM is to increase fault tolerance towards crashes. The goal is to retain main memory content even in case of a crash, for instance by an abrupt power loss {molina}. This way, critical data such as logs of file systems (also journals) or databases remain durable and can be used to recover and even complete unfinished operations such as making a transaction durable {harp, rio}. Furthermore, NVRAM can be used to create durable disk caches, hence shrinking the window in which disk IO is vulnerable to crashes {rio, envy}. In the past, such solutions relied on battery-backed DRAM or SRAM. This was subject to criticism as batteries only have a limited charge to ensure durability. Also batteries degrade over time and need to be maintained to prevent unexpected failure {molina}. Therefore, modern NVRAM solutions which no longer require peripherals are a welcome improvement in this area.

A significant amount of research on NVRAM is dedicated to mitigating the IO bottleneck imposed by traditional disk storage. One way to do so is to defer disk IO via durable disk caches {rio, envy}. When an object on disk is requested it is moved to the disk cache. Once an object is cached it may be read or modified with accessing the underlying disk. In theory, write-back is only required when there is not enough space for an incoming cache item. This way, frequently used objects incur no latency penalty through disk IO. Many operating systems, such as Linux or BSD implement such mechanisms where it is usually referred to as page buffer {quote?}. The difference is that conventional page buffers are volatile and need to be flushed at some point which requires careful resource management.

Another approach is to treat NVRAM as an equivalent to traditional disk storage. Early works which were strongly influenced by the lack of high-capacity NVRAM proposed hybrid storage systems where disk storage was used in conjunction with NVRAM {conquest, hermes}. These works have very similar assignment policies in that they only store small files such as  metadata or libraries in NVRAM whereas larger files remain on disk. While this does not remove disk access as a common bottleneck it certainly alleviates latency for some frequently accessed files. In this regard, NVRAM-complemented disk storage systems are similar to those with NVRAM disk caches.

A more rigorous implementation of the paradigm of NVRAM-assisted mass storage is to remove all traditional storage and rely solely on NVRAM. A prominent use case for this architecture are MMDB from traditional databases {hana, sofort, hyrise-nv} to key-value stores {echo, nvht, nvmcached}. Such databases keep all data in main memory and only use disks for recovery in case of crash. Recovery measures such as logging have been a long-standing issue with MMDB as they incur expensive disk IO, thus limiting the overall throughput. With NVRAM, disk IO can be eliminated allowing for faster logging and recovery using the main memory bandwidth. This concept is especially promising as some upcoming variants of NVRAM are projected to feature larger capacities than conventional DRAM {quote!}. Another notable example is *Machine* {hp, courtland}, a novel computer architecture which comprises a cluster of special purpose processors and large amounts of NVRAM.

### Further Applications

It was shown in various works that advantages can be gained by using NVRAM. Still, most proposals assume the presence volatile RAM in addition to NVRAM {oukid17}. The reason behind this assumption is that not all parts of memory are intended to be durable. This is true for regions capturing machine state or security-relevant data. Nonetheless, recent research suggests that systems exclusively based on NVRAM can be built {narayanan2012}. Clearly, such an architecture would have severe consequences for both operating systems and applications {bailey2011}. For example, operating system processes would remain in memory even if terminated. On the one hand, this could  significantly accelerate the procedure of invoking a process. On the other hand, all data belonging to a process' address space would be durable even if they were corrupted by a crash. Other issues are concerned about memory management, device drivers, and vital information. An early prototype of such a system is currently in development {hp, courtland}. This topic however, is beyond the scope of this work and is not subject to further discussion.

In a more recent effort to aid machine learning, it has been proposed to implement artificial neural networks by means of NVRAM {fumarola}. ANN perform a weighted sum over all inputs while an activation function acts as a classifier. For this to work, ANN need to be trained by properly adjusting the scalar weights. It has been suggested that this process could be performed directly in NVRAM where updated weights would be durable without the need for write-back. This is expected to substantially accelerate machine learning.