Transactions are a powerful concept that has been adopted in various branches of computer science. With transactions, multiple operations, such as reading or updating a record, can be grouped into a single unit that succeeds if and only if neither of its operations fails. Especially in high-performance computing environments, the utilization of computing resources through concurrent transactions plays an essential role.

This section introduces the concept of transactions and its properties with regard to concurrency, in particular.

### Definition

A transaction is a sequence of operations that is treated as single atomic operation, i.e. it either succeeds if all its suboperations succeed or it fails. In general, an incomplete or failed transaction must not have any observable side effects. A transaction *commits* when all its subordinate operations have completed. Once this process is complete, the transaction is *committed* and all its side effects, if any, become visible.

In general, the concept of a transaction does not impose any restrictions on the kind of operation enclosed inside a transaction. That is, apart from primitive operations such as read or update, transactions may also consist of transactions as well. This concept is known as *nested* transactions. In contrast, only primitive operations are permitted for *flat* transactions. Since nested transactions are more complex in their nature and have not been widely adopted, they are not subject of this work {?}. Unless stated otherwise, the term transaction always refers to flat transactions.

Transactions are useful when a series of operations must either execute in conjunction or not at all. A simple example is the transfer of money from one bank account to another. The action of withdrawing and depositing a specified value comprises two separate actions that must be successful in conjunction or not at all. Still, as shown later, even single operations can benefit from transactional semantics.

### Transactional Semantics

The previous definition of transactions was of rather intuitive nature. However, in order to be useful the semantics of a transaction need to be described more precisely. The predominant characterization of transactional semantics is ACID {haerder1983}. It comprises a set of necessary properties:

* atomicity
* consistency
* isolation
* durability

Atomicity captures the notion of all-or-nothing, i.e. either all operations of a transactional context succeed or none at all. As a consequence, any already completed operation of a transaction must be undone if the latter fails. Reverting the affected data to their previous state is often referred to as *rollback*.

The property of consistency asserts that if the underlying data are in a consistent state, then any transaction must preserve consistency. For example, an ACID-compliant database cannot be transitioned into an illegal state by means of a transaction. If a transaction is bound to break the consistency of the database, then it has to be aborted and rolled back.

In case multiple transactions are executed concurrently, each transaction could observe intermediate side effects of other concurrent transactions. In order to prevent this scenario and ensure the consistency property, isolation precludes transactions from seeing any concurrent activity. The property of isolation is later dealt with in more detail.

The last of the four ACID properties is durability. It ensures that all side effects incurred by a committed transaction must be durable across any subsequent system failure. Durability can be very hard to enforce, especially in the face of catastropic failures with failing backup media. Therefore, its notion is usually relaxed to a practically reasonable extent.

The ACID properties have become the prevalent reference for characterizing transactional systems. However, not all systems enforce the complete set of properties. Notable examples are transactional memory for conventional RAM and some cache-like databases which do not support durability as they are volatile by design. In other cases, guarantees are not dropped but relaxed. A prominent example for relaxation that is also fundamental to this thesis is the isolation of concurrent transactions.

### Serial Transactions

In a serial transaction-processing system all transactions are executed in a sequential order. That is, only one transaction, if any, is being executed at a time and overlapping is not possible. If a transaction t1 attempts to start while another transaction t0 is still active then t1 has to wait until t0 terminates.

This reveals two important drawbacks. First, transaction throughput does not scale as the number of overlapping transaction requests increases. Second, with only one computing resource active at a time, resource utilization is low on multi-core architectures. The same is true on single-core systems as execution latencies cannot be hidden by switching to other transactions. To mitigate these issues, transactions can be allowed to run concurrently.

### Concurrent Transactions

Concurrent transaction execution can largely remove the shortcomings outlined above. Now, an incoming transaction does not need to wait for an in-flight transaction to complete. In addition to increasing transaction throughput it also enables better resource utilization. This works as long as data are read but not written. Allowing concurrent updates however, bears potential conflicts that threaten the consistency of data and must therefore be addressed. Possible conflicts are:

* write-write
* write-read
* read-write

When a transaction t1 attempts to update a record A that was previously written but not committed by another transaction t2 then t1's update could overwrite t2's update to A before it has become visible. Unaware of the condition t2 will successfully commit even though its update is lost. This situation is called a *write-write* conflict.

t1: -------w(A)-commit---------
t2: --w(A)---- ... ----commit-- (update is lost)

In a *write-read* conflict occurs when a transaction reads data that has not been committed yet. Imagine a transaction t1 that reads a record A that was previously updated but not committed by another transaction t2. If t2 updates the same item again or fails, then t1 has read a value that was never committed. This situation is also called *dirty read*.

t1: -------r(A)-w(B)-commit-- (B is inconsistent to committed A)
t2: --w(A)--- !!! ----------- (update to A was rolled back)

The last conflict is called *read-write* conflict and denotes a situation when a transaction updates a record that was previously read by another transaction that is still running. Consider two transactions t1, t2 where t1 reads a record A which is later updated before either transaction commits. If t1 reads A again, then the result may be inconsistent with the earlier read. The situation is also referred to as *inconsistent read* or *non-repeatable read*.

t1: --r(A)--- ... ---r(A)--------- (has read inc. values of A)
t2: ----------w(A)--------commit--

It is important to note that the conflicts explained above are not precluded by protecting individual read or update operations.

[Explain consistency in transactional sense vs. race conditions]

With regard to data integrity it is imperative to ensure isolation by preventing these conflicts.

### Serializability

A core concept to preserve consistency in the presence of concurrent transactions is *serializability*. It is based on the observation that in an ACID-compliant serial transaction processing system, every sequence of transactions always yields consistent data. Likewise, a schedule of concurrent transactions should yield consistent data if and only if it behaves in a way that is equivalent to a serial sequence of the same transactions. More precisely, if and only if a concurrent schedule produces the same output as a serial schedule would have then there are no inconsistencies. This leads to the formal definition of serializability.

A concurrent schedule is called *serializable* if and only if there exists a serial schedule of the same transactions that produces the same output. A transaction processing system provides serializability if and only if it guarantees that all concurrent schedules are serializable.

[Examples]

In order to enforce serializability, a decidable classification for serial transaction schedules is required. A naive approach would be to search for equivalent serial schedules whenever needed. However, the complexity of searching for such a schedule grows exponentially, thus making this approach infeasible. Therefore, more pragmatic approaches were designed.

An early definition of serializability was given in ANSI SQL {sql1992}. The idea is to identify and detect *anomalies* of non-serializable schedules at runtime. If an anomaly is detected then any affected transaction must fail. Based on whether these anomalies were permitted, several *isolation levels* were defined. In terms of ANSI SQL, a transaction was serializable if none of the following anomalies was present:

* dirty read
* non-repeatable read
* phantom

A phantom is similar to a non-repeatable read but differs in that the item in question is not modified but added or removed. Imagine a transaction t1 making a conditional selection of items. If another transaction t2 adds an item and t1 repeats its selection then the result may contain the item which is inconsistent with the first result.

Note that this formalization is built around the observable artifacts of non-serializable schedules, rather than their cause such as read-write conflicts. While it is pragmatic to address only observable anomalies it also unreliable as more complicated consistencies may remain undetected. In fact, it was later found that the above characterization is insufficient as further anomalies were discovered {berenson1995critique, fekete2004read}. In the wake of these findings, additional restrictions were imposed on the notion of serializability.

Nevertheless, all of the discovered anomalies can be attributed to the access conflicts shown above. For example, the most recently discovered anomalies, *write skew* and *non-serializable read-only* are essentially results of read-write conflicts. In this sense, a transaction is serializable if and only if all possible conflicts are precluded. This characterization has several advantages. Most importantly, it is more plausible to discuss non-serializable schedules in terms of causes instead of effects. In addition, as opposed to anomalies the number of conflicts is smaller and also fixed. Therefore, this thesis primariliy defines serializability in terms of conflicts.
